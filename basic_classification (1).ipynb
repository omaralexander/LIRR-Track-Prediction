{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "D-vL20kRvokh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import LSTM\n",
        "from matplotlib import pyplot\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dy19brsAv1q6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "raw_data = pd.read_csv('MTA_DELAY_DATA (1).csv')\n",
        "\n",
        "df_majority = raw_data[raw_data['RESULT']==0].iloc[1:-2,0:3].dropna()\n",
        "df_minority = raw_data[raw_data['RESULT']==1].iloc[1:-2,0:3].dropna()\n",
        "print(raw_data['RESULT'].value_counts())\n",
        "\n",
        "\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=3475,   # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        " \n",
        "# Display new class counts\n",
        "print(df_downsampled['RESULT'].value_counts())\n",
        "print(numpy.unique(df_downsampled['RESULT']))\n",
        "\n",
        "X = df_downsampled.iloc[1:-2,0:2].dropna()\n",
        "Y = df_downsampled.iloc[1:-2,2:3].dropna()\n",
        "\n",
        "X, XTest, Y, YTest = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "print(YTest['RESULT'].value_counts()) #Just a double check to make sure the test data is balanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z7kSJMZAv4Cx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(activation):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128,activation=activation,input_dim =2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(64,activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(32,activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(16,activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001),metrics=['accuracy'])  \n",
        "\n",
        "    return model\n",
        "model = create_model('softsign')\n",
        "history = model.fit(X,Y,epochs=1500,batch_size=15, shuffle = True,validation_data = (XTest,YTest), verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FdVj8k6aq_L1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(activation):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128,activation=activation,input_dim =2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(64,activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(32,activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(16,activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001),metrics=['accuracy'])  \n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model,epochs=500,batch_size=15)\n",
        "\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(activation=activation)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X,Y,shuffle = True,validation_data = (XTest,YTest), verbose = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLUsW-dotPI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCvwDVLprO5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(8, kernel_initializer='uniform', activation='tanh',input_dim =2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(16, kernel_initializer='uniform', activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(32, kernel_initializer='uniform', activation='tanh'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001),metrics=['accuracy'])  \n",
        "\n",
        "history = model.fit(X,Y,epochs=500,batch_size=5, shuffle = True, validation_split = 0.0, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cZ-Q7WfQv-n4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "predict = model.predict_classes(X)\n",
        "print(numpy.unique(predict))\n",
        "\n",
        "for index,val in enumerate(predict):\n",
        "  print(\"Predicted: %s, actual: %s, for val %s\" % (val[0],Y.iloc[index].values,X.iloc[index].values))\n",
        "\n",
        "predict = [val[0] for val in predict]\n",
        "\n",
        "print(\"ras score: \",roc_auc_score(Y,predict))\n",
        "\n",
        "\n",
        "#predict = model.predict(numpy.array([0.0,0.12]).reshape(-1,2))\n",
        "#print(\"Probability of delay: \",predict[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQ3MeBvywIt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('model train vs validation loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}